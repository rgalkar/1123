{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/questions.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "#import data\n",
    "data = pd.read_csv('/kaggle/input/questions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check slice of data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    255045\n",
       "1    149306\n",
       "Name: is_duplicate, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distribution of data for different class\n",
    "data.is_duplicate.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data:  404351\n",
      "shape of data:  (404351, 6)\n"
     ]
    }
   ],
   "source": [
    "print('length of data: ', len(data))\n",
    "print('shape of data: ', data.shape)\n",
    "#no of entries in data is 405k which is quiet high \n",
    "#so we can perform analysis on subset of data to save excecution time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking subset of data \n",
    "df = data[:50000] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              0\n",
       "qid1            0\n",
       "qid2            0\n",
       "question1       0\n",
       "question2       0\n",
       "is_duplicate    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking Nan values if any\n",
    "df.isna().sum()\n",
    "#we dont have any Nan values in subset of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the step by step guide to invest in share market in india?\n",
      "What is the step by step guide to invest in share market?\n",
      "\n",
      "What is the story of Kohinoor (Koh-i-Noor) Diamond?\n",
      "What would happen if the Indian government stole the Kohinoor (Koh-i-Noor) diamond back?\n",
      "\n",
      "How can I increase the speed of my internet connection while using a VPN?\n",
      "How can Internet speed be increased by hacking through DNS?\n",
      "\n",
      "Why am I mentally very lonely? How can I solve it?\n",
      "Find the remainder when [math]23^{24}[/math] is divided by 24,23?\n",
      "\n",
      "Which one dissolve in water quikly sugar, salt, methane and carbon di oxide?\n",
      "Which fish would survive in salt water?\n",
      "\n",
      "Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?\n",
      "I'm a triple Capricorn (Sun, Moon and ascendant in Capricorn) What does this say about me?\n",
      "\n",
      "Should I buy tiago?\n",
      "What keeps childern active and far from phone and video games?\n",
      "\n",
      "How can I be a good geologist?\n",
      "What should I do to be a great geologist?\n",
      "\n",
      "When do you use シ instead of し?\n",
      "When do you use \"&\" instead of \"and\"?\n",
      "\n",
      "Motorola (company): Can I hack my Charter Motorolla DCX3400?\n",
      "How do I hack Motorola DCX3400 for free internet?\n",
      "\n",
      "Method to find separation of slits using fresnel biprism?\n",
      "What are some of the things technicians can tell about the durability and reliability of Laptops and its components?\n",
      "\n",
      "How do I read and find my YouTube comments?\n",
      "How can I see all my Youtube comments?\n",
      "\n",
      "What can make Physics easy to learn?\n",
      "How can you make physics easy to learn?\n",
      "\n",
      "What was your first sexual experience like?\n",
      "What was your first sexual experience?\n",
      "\n",
      "What are the laws to change your status from a student visa to a green card in the US, how do they compare to the immigration laws in Canada?\n",
      "What are the laws to change your status from a student visa to a green card in the US? How do they compare to the immigration laws in Japan?\n",
      "\n",
      "What would a Trump presidency mean for current international master’s students on an F1 visa?\n",
      "How will a Trump presidency affect the students presently in US or planning to study in US?\n",
      "\n",
      "What does manipulation mean?\n",
      "What does manipulation means?\n",
      "\n",
      "Why do girls want to be friends with the guy they reject?\n",
      "How do guys feel after rejecting a girl?\n",
      "\n",
      "Why are so many Quora users posting questions that are readily answered on Google?\n",
      "Why do people ask Quora questions which can be answered easily by Google?\n",
      "\n",
      "Which is the best digital marketing institution in banglore?\n",
      "Which is the best digital marketing institute in Pune?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#printing few question pairs in the datset\n",
    "for i in range(0,20):\n",
    "    print(df.question1[i])\n",
    "    print(df.question2[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "import scipy #library for scientific calculations\n",
    "import datetime\n",
    "import nltk\n",
    "from sklearn import re\n",
    "from sklearn import pipeline\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning text in question\n",
    "\n",
    "# This list is so extensive that we can look back at it as a reference when \n",
    "# needed for other regular expression related work.\n",
    "\n",
    "SPECIAL_TOKENS = {'non-ascii': 'non_ascii_word'}\n",
    "\n",
    "def normalized_text(text, stem_words=True):\n",
    "    def pad_str(s):\n",
    "        return ' '+s+' '\n",
    "    \n",
    "    if pd.isnull(text):  #If null\n",
    "        return ''\n",
    "\n",
    "    # Empty question\n",
    "    \n",
    "    if type(text) != str or text=='':  #if text type is not string\n",
    "        return ''\n",
    "\n",
    "    # Clean the text\n",
    "    text = re.sub(\"\\'s\", \" \", text) # we have cases like \"Sam is\" or \"Sam's\" (i.e. his) these two cases aren't separable, I choose to compromise are kill \"'s\" directly\n",
    "    text = re.sub(\" whats \", \" what is \", text, flags=re.IGNORECASE) # replace whats by what is and ignore case\n",
    "    text = re.sub(\"\\'ve\", \" have \", text) # replace 've by have\n",
    "    text = re.sub(\"can't\", \"can not\", text) # replace can't by can not\n",
    "    text = re.sub(\"n't\", \" not \", text) # replace n't by not\n",
    "    text = re.sub(\"i'm\", \"i am\", text, flags=re.IGNORECASE) # replace i'm by i am and ignore case\n",
    "    text = re.sub(\"\\'re\", \" are \", text) # replace 're by are\n",
    "    text = re.sub(\"\\'d\", \" would \", text) # replace 'd by would\n",
    "    text = re.sub(\"\\'ll\", \" will \", text) # replace 'll by will\n",
    "    text = re.sub(\"e\\.g\\.\", \" eg \", text, flags=re.IGNORECASE) # replace e.g. by eg and ignore case\n",
    "    text = re.sub(\"b\\.g\\.\", \" bg \", text, flags=re.IGNORECASE) # replace b.g. by bg and ignore case\n",
    "    text = re.sub(\"(\\d+)(kK)\", \" \\g<1>000 \", text) \n",
    "    text = re.sub(\"e-mail\", \" email \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(\"(the[\\s]+|The[\\s]+)?U\\.S\\.A\\.\", \" America \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(\"(the[\\s]+|The[\\s]+)?United State(s)?\", \" America \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(\"\\(s\\)\", \" \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(\"[c-fC-F]\\:\\/\", \" disk \", text)\n",
    "    \n",
    "    # remove comma between numbers, i.e. 15,000 -> 15000\n",
    "    text = re.sub('(?<=[0-9])\\,(?=[0-9])', \"\", text)\n",
    "    \n",
    "    # add padding to punctuations and special chars, we still need them later\n",
    "    text = re.sub('\\$', \" dollar \", text)\n",
    "    text = re.sub('\\%', \" percent \", text)\n",
    "    text = re.sub('\\&', \" and \", text)\n",
    "    \n",
    "    text = re.sub('[^\\x00-\\x7F]+', pad_str(SPECIAL_TOKENS['non-ascii']), text) \n",
    "    \n",
    "    # Indian Currency\n",
    "    text = re.sub(\"(?<=[0-9])rs \", \" rs \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(\" rs(?=[0-9])\", \" rs \", text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # cleaning text rules from : https://www.kaggle.com/currie32/the-importance-of-cleaning-text\n",
    "    text = re.sub(r\" (the[\\s]+|The[\\s]+)?US(A)? \", \" America \", text)\n",
    "    text = re.sub(r\" UK \", \" England \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" india \", \" India \", text)\n",
    "    text = re.sub(r\" switzerland \", \" Switzerland \", text)\n",
    "    text = re.sub(r\" china \", \" China \", text)\n",
    "    text = re.sub(r\" chinese \", \" Chinese \", text) \n",
    "    text = re.sub(r\" imrovement \", \" improvement \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" intially \", \" initially \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" quora \", \" Quora \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" dms \", \" direct messages \", text, flags=re.IGNORECASE)  \n",
    "    text = re.sub(r\" demonitization \", \" demonetization \", text, flags=re.IGNORECASE) \n",
    "    text = re.sub(r\" actived \", \" active \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" kms \", \" kilometers \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" cs \", \" computer science \", text, flags=re.IGNORECASE) \n",
    "    text = re.sub(r\" upvote\", \" up vote\", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" iPhone \", \" phone \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" \\0rs \", \" rs \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" calender \", \" calendar \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" ios \", \" operating system \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" gps \", \" GPS \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" gst \", \" GST \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" programing \", \" programming \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" bestfriend \", \" best friend \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" dna \", \" DNA \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" III \", \" 3 \", text)\n",
    "    text = re.sub(r\" banglore \", \" Banglore \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" J K \", \" JK \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" J\\.K\\. \", \" JK \", text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # replace the float numbers with a random number\n",
    "    \n",
    "    text = re.sub('[0-9]+\\.[0-9]+', \" 87 \", text)\n",
    "  \n",
    "    #Removing Punctuations\n",
    "    text = [word for word in text if word not in punctuation]\n",
    "    text = ''.join(text)\n",
    "    text = text.lower()\n",
    "       \n",
    "    # Return a list of words\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#applying text cleaning function to question text\n",
    "df['question1'] = df['question1'].apply(normalized_text)\n",
    "df['question2'] = df['question2'].apply(normalized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is the step by step guide to invest in share market in india\n",
      "what is the step by step guide to invest in share market\n",
      "\n",
      "what is the story of kohinoor kohinoor diamond\n",
      "what would happen if the indian government stole the kohinoor kohinoor diamond back\n",
      "\n",
      "how can i increase the speed of my internet connection while using a vpn\n",
      "how can internet speed be increased by hacking through dns\n",
      "\n",
      "why am i mentally very lonely how can i solve it\n",
      "find the remainder when math2324math is divided by 2423\n",
      "\n",
      "which one dissolve in water quikly sugar salt methane and carbon di oxide\n",
      "which fish would survive in salt water\n",
      "\n",
      "astrology i am a capricorn sun cap moon and cap risingwhat does that say about me\n",
      "i am a triple capricorn sun moon and ascendant in capricorn what does this say about me\n",
      "\n",
      "should i buy tiago\n",
      "what keeps childern active and far from phone and video games\n",
      "\n",
      "how can i be a good geologist\n",
      "what should i do to be a great geologist\n",
      "\n",
      "when do you use  nonasciiword  instead of  nonasciiword \n",
      "when do you use  and  instead of and\n",
      "\n",
      "motorola company can i hack my charter motorolla dcx3400\n",
      "how do i hack motorola dcx3400 for free internet\n",
      "\n",
      "method to find separation of slits using fresnel biprism\n",
      "what are some of the things technicians can tell about the durability and reliability of laptops and its components\n",
      "\n",
      "how do i read and find my youtube comments\n",
      "how can i see all my youtube comments\n",
      "\n",
      "what can make physics easy to learn\n",
      "how can you make physics easy to learn\n",
      "\n",
      "what was your first sexual experience like\n",
      "what was your first sexual experience\n",
      "\n",
      "what are the laws to change your status from a student visa to a green card in the us how do they compare to the immigration laws in canada\n",
      "what are the laws to change your status from a student visa to a green card in the us how do they compare to the immigration laws in japan\n",
      "\n",
      "what would a trump presidency mean for current international master nonasciiword s students on an f1 visa\n",
      "how will a trump presidency affect the students presently in america or planning to study in us\n",
      "\n",
      "what does manipulation mean\n",
      "what does manipulation means\n",
      "\n",
      "why do girls want to be friends with the guy they reject\n",
      "how do guys feel after rejecting a girl\n",
      "\n",
      "why are so many quora users posting questions that are readily answered on google\n",
      "why do people ask quora questions which can be answered easily by google\n",
      "\n",
      "which is the best digital marketing institution in banglore\n",
      "which is the best digital marketing institute in pune\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#checking the cleaned text to see changes made\n",
    "for i in range(0,20):\n",
    "    print(df.question1[i])\n",
    "    print(df.question2[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>what is the story of kohinoor kohinoor diamond</td>\n",
       "      <td>what would happen if the indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>how can i increase the speed of my internet co...</td>\n",
       "      <td>how can internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>why am i mentally very lonely how can i solve it</td>\n",
       "      <td>find the remainder when math2324math is divide...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>which one dissolve in water quikly sugar salt ...</td>\n",
       "      <td>which fish would survive in salt water</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  what is the step by step guide to invest in sh...   \n",
       "1   1     3     4     what is the story of kohinoor kohinoor diamond   \n",
       "2   2     5     6  how can i increase the speed of my internet co...   \n",
       "3   3     7     8   why am i mentally very lonely how can i solve it   \n",
       "4   4     9    10  which one dissolve in water quikly sugar salt ...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  what is the step by step guide to invest in sh...             0  \n",
       "1  what would happen if the indian government sto...             0  \n",
       "2  how can internet speed be increased by hacking...             0  \n",
       "3  find the remainder when math2324math is divide...             0  \n",
       "4             which fish would survive in salt water             0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data head\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 1. * *** Bag of Words + XGBOOST**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using word vector of word_count and frequency withpout capturing the meaning of word\n",
    "#r'\\w{1,}' indiactes 1 or more word\n",
    "\n",
    "CV = CountVectorizer(analyzer='word', stop_words='english', token_pattern=r'\\w{1,}')\n",
    "q1_trans = CV.fit_transform(df['question1'].values)\n",
    "q2_trans = CV.fit_transform(df['question2'].values)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scipy.sparse.hstack will stack sparse matrix columnwise, and stacking them side by side\n",
    "\n",
    "X = scipy.sparse.hstack((q1_trans, q2_trans))\n",
    "y = df.is_duplicate.values    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting traing set and test set for training and validating model for classification\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size = 0.30, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=0.7, eta=0.3, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=50,\n",
      "              min_child_weight=1, missing=None, n_estimators=80, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=4, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=1, subsample=0.8, verbosity=1)\n",
      "Confusion Matrix:\n",
      " [[8545  833]\n",
      " [3290 2332]]\n",
      "Accuracy score: \n",
      " 0.7251333333333333\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.91      0.81      9378\n",
      "           1       0.74      0.41      0.53      5622\n",
      "\n",
      "    accuracy                           0.73     15000\n",
      "   macro avg       0.73      0.66      0.67     15000\n",
      "weighted avg       0.73      0.73      0.70     15000\n",
      "\n",
      "F1 Score:\n",
      "  0.530784112894048\n",
      "Code run-time:  0:02:16.041230\n"
     ]
    }
   ],
   "source": [
    "#gradient Boosting Model used\n",
    "#start time\n",
    "st = datetime.datetime.now()\n",
    "\n",
    "classifier1 = XGBClassifier(max_depth=50, n_estimators=80, learning_rate=0.1, colsample_bytree=.7, gamma=0, reg_alpha=4, \n",
    "objective='binary:logistic', eta=0.3, silent=1, subsample=0.8)\n",
    "#fitting the model\n",
    "print(classifier1.fit(X_train, y_train))\n",
    "#predicting if pair is duplicate or not\n",
    "prediction_CV = classifier1.predict(X_test)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, prediction_CV))\n",
    "print(\"Accuracy score: \\n\", accuracy_score(y_test, prediction_CV))\n",
    "print(\"Classification report:\\n\", classification_report(y_test, prediction_CV))\n",
    "print(\"F1 Score:\\n \",f1_score(y_test, prediction_CV))\n",
    "\n",
    "et = datetime.datetime.now()\n",
    "print(\"Code run-time: \", et-st)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** ****TF-IDF (word level) + XGBOOST\n",
    "**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF vectorizer \n",
    "#5000 features were used for tfidf vectorizer\n",
    "#r'\\w{1,}'  indicates more than 1 word\n",
    "\n",
    "tfidf = TfidfVectorizer(analyzer='word', max_features=5000, token_pattern=r'\\w{1,}')\n",
    "\n",
    "q1word_trans = tfidf.fit_transform(df['question1'].values)\n",
    "q2word_trans = tfidf.fit_transform(df['question2'].values)\n",
    "\n",
    "X = scipy.sparse.hstack((q1word_trans,q2word_trans))\n",
    "y = df.is_duplicate.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test-split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size = 0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=0.7, eta=0.3, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=50,\n",
      "              min_child_weight=1, missing=None, n_estimators=80, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=4, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=1, subsample=0.8, verbosity=1)\n",
      "Confusion Matrix:\n",
      " [[8932 1400]\n",
      " [2835 3333]]\n",
      "Accuracy score: \n",
      " 0.7433333333333333\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.86      0.81     10332\n",
      "           1       0.70      0.54      0.61      6168\n",
      "\n",
      "    accuracy                           0.74     16500\n",
      "   macro avg       0.73      0.70      0.71     16500\n",
      "weighted avg       0.74      0.74      0.73     16500\n",
      "\n",
      "F1 Score:\n",
      "  0.6115035317860747\n",
      "Code run-time:  0:01:36.557736\n"
     ]
    }
   ],
   "source": [
    "# Xg Boost classifier for word level vectorizer\n",
    "\n",
    "st = datetime.datetime.now()\n",
    "\n",
    "classifier2 = XGBClassifier(max_depth=50, n_estimators=80, learning_rate=0.1, colsample_bytree=.7, gamma=0, reg_alpha=4, \n",
    "objective='binary:logistic', eta=0.3, silent=1, subsample=0.8)\n",
    "#fitting the model with traing data\n",
    "print(classifier2.fit(X_train, y_train))\n",
    "\n",
    "#predicting the test data\n",
    "prediction_tfidf = classifier2.predict(X_test)\n",
    "\n",
    "#Performance evaluation\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, prediction_tfidf))\n",
    "print(\"Accuracy score: \\n\", accuracy_score(y_test, prediction_tfidf))\n",
    "print(\"Classification report:\\n\", classification_report(y_test, prediction_tfidf))\n",
    "print(\"F1 Score:\\n \",f1_score(y_test, prediction_tfidf))\n",
    "\n",
    "et = datetime.datetime.now()\n",
    "print(\"Code run-time: \", et-st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ******ngram level TFIDF + XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF ngram level vectorizer \n",
    "#5000 features were used for tfidf vectorizer\n",
    "#r'\\w{1,}'  indicates more than 1 word\n",
    "#ngram_range = (1,3) means 2 and 3 features are used\n",
    "\n",
    "tfidf = TfidfVectorizer(analyzer='word',ngram_range=(1,3), max_features=5000, token_pattern=r'\\w{1,}')\n",
    "\n",
    "q1ngram_trans = tfidf.fit_transform(df['question1'].values)\n",
    "q2ngram_trans = tfidf.fit_transform(df['question2'].values)\n",
    "\n",
    "X = scipy.sparse.hstack((q1ngram_trans,q2ngram_trans))\n",
    "y = df.is_duplicate.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test-split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size = 0.30, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=0.7, eta=0.3, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=50,\n",
      "              min_child_weight=1, missing=None, n_estimators=80, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=4, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=1, subsample=0.8, verbosity=1)\n",
      "ngram_range Confusion Matrix:\n",
      " [[8095 1283]\n",
      " [2662 2960]]\n",
      "ngram_range Accuracy score: \n",
      " 0.737\n",
      "ngram_range Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.86      0.80      9378\n",
      "           1       0.70      0.53      0.60      5622\n",
      "\n",
      "    accuracy                           0.74     15000\n",
      "   macro avg       0.73      0.69      0.70     15000\n",
      "weighted avg       0.73      0.74      0.73     15000\n",
      "\n",
      "ngram_range F1 Score:\n",
      "  0.6001013684744045\n",
      "Code run-time:  0:02:10.131737\n"
     ]
    }
   ],
   "source": [
    "# Xg Boost classifier for ngram_range=(1,3) level vectorizer\n",
    "\n",
    "st = datetime.datetime.now()\n",
    "\n",
    "classifier3 = XGBClassifier(max_depth=50, n_estimators=80, learning_rate=0.1, colsample_bytree=.7, gamma=0, reg_alpha=4, \n",
    "objective='binary:logistic', eta=0.3, silent=1, subsample=0.8)\n",
    "#fitting the model with traing data\n",
    "print(classifier3.fit(X_train, y_train))\n",
    "\n",
    "#predicting the test data\n",
    "prediction_tfidf = classifier3.predict(X_test)\n",
    "\n",
    "#Performance evaluation\n",
    "print(\"ngram_range Confusion Matrix:\\n\", confusion_matrix(y_test, prediction_tfidf))\n",
    "print(\"ngram_range Accuracy score: \\n\", accuracy_score(y_test, prediction_tfidf))\n",
    "print(\"ngram_range Classification report:\\n\", classification_report(y_test, prediction_tfidf))\n",
    "print(\"ngram_range F1 Score:\\n \",f1_score(y_test, prediction_tfidf))\n",
    "\n",
    "et = datetime.datetime.now()\n",
    "print(\"Code run-time: \", et-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF ngram level vectorizer \n",
    "#5000 features were used for tfidf vectorizer\n",
    "#r'\\w{1,}'  indicates more than 1 word\n",
    "#ngram_range = (2,3) means 2 and 3 features are used\n",
    "\n",
    "tfidf = TfidfVectorizer(analyzer='word',ngram_range=(2,3), max_features=5000, token_pattern=r'\\w{1,}')\n",
    "\n",
    "q1ngram_trans = tfidf.fit_transform(df['question1'].values)\n",
    "q2ngram_trans = tfidf.fit_transform(df['question2'].values)\n",
    "\n",
    "X = scipy.sparse.hstack((q1ngram_trans,q2ngram_trans))\n",
    "y = df.is_duplicate.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test-split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size = 0.30, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=0.7, eta=0.3, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=50,\n",
      "              min_child_weight=1, missing=None, n_estimators=80, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=4, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=1, subsample=0.8, verbosity=1)\n",
      "ngram_range(2,3) Confusion Matrix:\n",
      " [[8282 1096]\n",
      " [3322 2300]]\n",
      "ngram_range(2,3) Accuracy score: \n",
      " 0.7054666666666667\n",
      "ngram_range(2,3) Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.88      0.79      9378\n",
      "           1       0.68      0.41      0.51      5622\n",
      "\n",
      "    accuracy                           0.71     15000\n",
      "   macro avg       0.70      0.65      0.65     15000\n",
      "weighted avg       0.70      0.71      0.68     15000\n",
      "\n",
      "ngram_range(2,3) F1 Score:\n",
      "  0.5100909292526059\n",
      "Code run-time:  0:01:10.703067\n"
     ]
    }
   ],
   "source": [
    "# Xg Boost classifier for ngram_range=(1,3) level vectorizer\n",
    "\n",
    "st = datetime.datetime.now()\n",
    "\n",
    "classifier4 = XGBClassifier(max_depth=50, n_estimators=80, learning_rate=0.1, colsample_bytree=.7, gamma=0, reg_alpha=4, \n",
    "objective='binary:logistic', eta=0.3, silent=1, subsample=0.8)\n",
    "#fitting the model with traing data\n",
    "print(classifier4.fit(X_train, y_train))\n",
    "\n",
    "#predicting the test data\n",
    "prediction_tfidf = classifier4.predict(X_test)\n",
    "\n",
    "#Performance evaluation\n",
    "print(\"ngram_range(2,3) Confusion Matrix:\\n\", confusion_matrix(y_test, prediction_tfidf))\n",
    "print(\"ngram_range(2,3) Accuracy score: \\n\", accuracy_score(y_test, prediction_tfidf))\n",
    "print(\"ngram_range(2,3) Classification report:\\n\", classification_report(y_test, prediction_tfidf))\n",
    "print(\"ngram_range(2,3) F1 Score:\\n \",f1_score(y_test, prediction_tfidf))\n",
    "\n",
    "et = datetime.datetime.now()\n",
    "print(\"Code run-time: \", et-st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Char level TFIDF + XGBOOST****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF ngram level vectorizer \n",
    "#5000 features were used for tfidf vectorizer\n",
    "#r'\\w{1,}'  indicates more than 1 word\n",
    "#ngram_range = (1,3) means 2 and 3 features are used\n",
    "#char level analyzer is used \n",
    "\n",
    "tfidf = TfidfVectorizer(analyzer='char',ngram_range=(1,3), max_features=5000, token_pattern=r'\\w{1,}')\n",
    "\n",
    "q1char_trans = tfidf.fit_transform(df['question1'].values)\n",
    "q2char_trans = tfidf.fit_transform(df['question2'].values)\n",
    "\n",
    "X = scipy.sparse.hstack((q1char_trans,q2char_trans))\n",
    "y = df.is_duplicate.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test-split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size = 0.30, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=0.7, eta=0.3, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=50,\n",
      "              min_child_weight=1, missing=None, n_estimators=80, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=4, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=1, subsample=0.8, verbosity=1)\n",
      "char level Confusion Matrix:\n",
      " [[8338 1040]\n",
      " [2600 3022]]\n",
      "char level Accuracy score: \n",
      " 0.7573333333333333\n",
      "char level Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.89      0.82      9378\n",
      "           1       0.74      0.54      0.62      5622\n",
      "\n",
      "    accuracy                           0.76     15000\n",
      "   macro avg       0.75      0.71      0.72     15000\n",
      "weighted avg       0.76      0.76      0.75     15000\n",
      "\n",
      "char level F1 Score:\n",
      "  0.624122263527468\n",
      "Code run-time:  0:09:57.123985\n"
     ]
    }
   ],
   "source": [
    "# Xg Boost classifier for char level vectorizer\n",
    "\n",
    "st = datetime.datetime.now()\n",
    "\n",
    "classifier5 = XGBClassifier(max_depth=50, n_estimators=80, learning_rate=0.1, colsample_bytree=.7, gamma=0, reg_alpha=4, \n",
    "objective='binary:logistic', eta=0.3, silent=1, subsample=0.8)\n",
    "#fitting the model with traing data\n",
    "print(classifier5.fit(X_train, y_train))\n",
    "\n",
    "#predicting the test data\n",
    "prediction_tfidf = classifier5.predict(X_test)\n",
    "\n",
    "#Performance evaluation\n",
    "print(\"char level Confusion Matrix:\\n\", confusion_matrix(y_test, prediction_tfidf))\n",
    "print(\"char level Accuracy score: \\n\", accuracy_score(y_test, prediction_tfidf))\n",
    "print(\"char level Classification report:\\n\", classification_report(y_test, prediction_tfidf))\n",
    "print(\"char level F1 Score:\\n \",f1_score(y_test, prediction_tfidf))\n",
    "\n",
    "et = datetime.datetime.now()\n",
    "print(\"Code run-time: \", et-st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Challenge was to create the model which can classify between similar question asked on quora##\n",
    "\n",
    "### text processing used is so extensive that we can use it as a reference when \n",
    "# needed for other regular expression related work.###\n",
    "\n",
    "### Initially Bag of Words model is used for vectorization with XGBOOST for classification\n",
    "\n",
    "### TFIDF vectorizer at word level, n-Gram level, Char level is used.\n",
    "\n",
    "### Without sentiment capturing, best accuracy of 75.73% is achieved using \n",
    "###extreme gradient boosting on character level TF-IDF...."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
